{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "import pickle\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, coo_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fixes the broken bson dependency that hyperopt can have\n",
    "from hyperopt import base\n",
    "base.have_bson = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General notes\n",
    "In this notebook, we build a basic TF-IDF model to identify Alice and then do it again with feature engineering and data cleaning. Finally, we perform hyperparameter optimization to get the final model.\n",
    "The results are reflected in the article mentioned in the repository readme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "We'll need some functions to explore the data. Lets put them here to keep the code organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by yorko - lead organizer of MLCourse\n",
    "# Function for writing predictions to a submission file\n",
    "# Source: https://www.kaggle.com/kashnitsky/correct-time-aware-cross-validation-scheme\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    Predicted labels: array of Alice probabilities\n",
    "    out_file: path to the output file\n",
    "    \n",
    "    Out:\n",
    "    None: saves results to out_file, returns nothing\n",
    "    \n",
    "    \n",
    "    Function writes the results to a csv file that is ready to be submitted\n",
    "    into the competition.\n",
    "    Docstring by Alex Kirko.\n",
    "    \"\"\"\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for TF_IDF\n",
    "\n",
    "def form_sentences(in_list):\n",
    "    \"\"\"\n",
    "    Makes rows for the CountVectorizer to process.\n",
    "    Is made to use with apply. Works by casting floats as strings\n",
    "    ignoring NaNs, and joining the strings with whitespace.\n",
    "    \n",
    "    Args:\n",
    "    in_list (DataFrame row): row of identifiers/site names to join\n",
    "    \"\"\"\n",
    "    \n",
    "    str_list = [str(x) for x in in_list if ~pd.isnull(x)]\n",
    "    return ' '.join(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_basic(string):\n",
    "    \"\"\"\n",
    "    Performs basic tokenization: splits only by whitespace.\n",
    "    \n",
    "    Args:\n",
    "    string (str): string to be tokenized\n",
    "    Out:\n",
    "    (list): list of tokens\n",
    "    \"\"\"\n",
    "    return string.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_domain_name(string):    \n",
    "    \"\"\"\n",
    "    Extracts domain names from a website list string.\n",
    "    \n",
    "    Args:\n",
    "    string (str): string to be tokenized\n",
    "    Out:\n",
    "    domains (list): list of tokens\n",
    "    \"\"\"\n",
    "    sites = string.split(' ')\n",
    "    domains = []\n",
    "    for site in sites:\n",
    "        try:\n",
    "            domain_name = site.split('.')[-2]\n",
    "        except:\n",
    "            domain_name = site\n",
    "        domains.append(domain_name)\n",
    "    return domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_subdom(string):\n",
    "    \"\"\"\n",
    "    Extracts domains and subdomains from a website list string.\n",
    "    \n",
    "    Args:\n",
    "    string (str): string to be tokenized\n",
    "    Out:\n",
    "    subdomains + domains + dom/subdom combinations(list): list of tokens\n",
    "    \"\"\"\n",
    "    sites = string.split(' ')\n",
    "    subdomains = []\n",
    "    domains = []\n",
    "    dom_subdom = []\n",
    "    for site in sites:\n",
    "        try:\n",
    "            domains.append(site.split('.')[-2])\n",
    "            dom_subdom.append(site.split('.')[-2])\n",
    "            subdomains.append(site.split('.')[-3])\n",
    "            dom_subdom.append(site.split('.')[-3])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return subdomains + domains + dom_subdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_stats(string):\n",
    "    \"\"\"\n",
    "    Calcs the number of subdomains in a session,\n",
    "    and the fraction of unique subdomains in a session,\n",
    "    also the number of domains and fraction of unique\n",
    "    domains\n",
    "    Args:\n",
    "    string (str): sequence of websites encoded in a string\n",
    "    \"\"\"\n",
    "    sites = string.split(' ')\n",
    "    subdomains = []\n",
    "    domains = []\n",
    "    for site in sites:\n",
    "        try:\n",
    "            domains.append(site.split('.')[-2])\n",
    "            subdomains.append(site.split('.')[-3])\n",
    "        except:\n",
    "            pass\n",
    "    #print(domains)\n",
    "    #print(subdomains)\n",
    "    dom_cnt = len(domains)\n",
    "    subdom_cnt = len(subdomains)\n",
    "    #print((dom_cnt, subdom_cnt))\n",
    "    if dom_cnt:\n",
    "        dom_unique = len(set(domains)) / dom_cnt\n",
    "    else:\n",
    "        dom_unique = 1\n",
    "        \n",
    "    if subdom_cnt:\n",
    "        subdom_unique = len(set(subdomains)) / subdom_cnt\n",
    "    else:\n",
    "        subdom_unique = 1\n",
    "    return ((dom_cnt, dom_unique),(subdom_cnt, subdom_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TEST_SIZE = 0.1\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 7\n",
    "SKIP_FOLDS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Basic TF-IDF. No feature engineering or hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test data sets, change paths if needed\n",
    "PATH_TO_DATA = Path('data/')\n",
    "\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv(PATH_TO_DATA / 'train_sessions.csv',\n",
    "                       index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv(PATH_TO_DATA / 'test_sessions.csv',\n",
    "                      index_col='session_id', parse_dates=times)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace site ids with site names\n",
    "site_dic = pickle.load(open(PATH_TO_DATA / 'site_dic.pkl','rb'))\n",
    "\n",
    "# Make swap ids with values: make site ids dict keys\n",
    "site_dic = {val: key for val, key in zip(site_dic.values(), site_dic.keys())}\n",
    "\n",
    "# Replace site ids with domain names for both train and test\n",
    "train_df[sites] = train_df[sites].applymap(lambda x: site_dic[x] if x in site_dic else x)\n",
    "test_df[sites] = test_df[sites].applymap(lambda x: site_dic[x] if x in site_dic else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off target\n",
    "y = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_strings = full_df[sites].apply(form_sentences, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = tokenize_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_pipeline = Pipeline([\n",
    "        ('site_bag',Pipeline([\n",
    "            ('vect',CountVectorizer(tokenizer=tokenize,max_features=50000, ngram_range=(1,3))),\n",
    "            ('tfidf',TfidfTransformer())\n",
    "        ])),\n",
    "    ('clf',LogisticRegression(C=1, \n",
    "                              solver='liblinear',random_state=RANDOM_STATE,class_weight=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC score for the basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = full_sites_strings.iloc[:idx_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70242979, 0.79771246, 0.79432459, 0.88165145, 0.88242881,\n",
       "       0.88452159, 0.92673304])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_splitter = TimeSeriesSplit(n_splits=N_FOLDS)\n",
    "cv_res = cross_val_score(estimator=basic_pipeline,X=all_train_data,y=y,cv=ts_splitter,n_jobs=7,scoring='roc_auc')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic model cross-validation ROC AUC score is 0.8739318976276982\n"
     ]
    }
   ],
   "source": [
    "print('Basic model cross-validation ROC AUC score is {}'.format(np.mean(cv_res[SKIP_FOLDS:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Basic TF-IDF + feature engineering and data cleaning. No hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and test data sets, change paths if needed\n",
    "PATH_TO_DATA = Path('data/')\n",
    "\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df = pd.read_csv(PATH_TO_DATA / 'train_sessions.csv',\n",
    "                       index_col='session_id', parse_dates=times)\n",
    "test_df = pd.read_csv(PATH_TO_DATA / 'test_sessions.csv',\n",
    "                      index_col='session_id', parse_dates=times)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace site ids with site names\n",
    "site_dic = pickle.load(open(PATH_TO_DATA / 'site_dic.pkl','rb'))\n",
    "\n",
    "# Make swap ids with values: make site ids dict keys\n",
    "site_dic = {val: key for val, key in zip(site_dic.values(), site_dic.keys())}\n",
    "\n",
    "# Replace site ids with domain names for both train and test\n",
    "train_df[sites] = train_df[sites].applymap(lambda x: site_dic[x] if x in site_dic else x)\n",
    "test_df[sites] = test_df[sites].applymap(lambda x: site_dic[x] if x in site_dic else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load - remove abnormal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove everything before 12th of November\n",
    "# This is because before this date data comes only on the 12th day of month\n",
    "# and it decreases ROC AUC\n",
    "train_df = train_df[train_df['time1']> datetime(2013,11,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove months where there were no Alice attacks from the train dataset: \n",
    "# Alice just didn't show up in these months, so the data is noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['start_yearmonth'] = train_df[times].min(axis=1).apply(lambda x: x.year*100 + x.month)\n",
    "alice_by_month = train_df.groupby(by=['start_yearmonth'])['target'].sum()\n",
    "months_to_drop = alice_by_month[alice_by_month==0].index.tolist()\n",
    "train_df = train_df[~train_df['start_yearmonth'].isin(months_to_drop)]\n",
    "train_df = train_df.drop('start_yearmonth',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off target\n",
    "y = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing - basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off target\n",
    "y = train_df['target']\n",
    "\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sites_strings = full_df[sites].apply(form_sentences, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "For reasoning that led to this set of features, see `visual_exploration.ipynb`. Among the ideas listed there, I picked ones that gave higher scores on cross-validation and Public Leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_feats = pd.DataFrame(index=full_df.index)\n",
    "\n",
    "extra_feats['session_length'] = (full_df[times].max(axis=1) - full_df[times].min(axis=1))/np.timedelta64(1, 's')\n",
    "extra_feats['start_hour'] = full_df[times].min(axis=1).apply(lambda x: (x.hour))\n",
    "extra_feats['start_minute'] = full_df[times].min(axis=1).apply(lambda x: (x.minute))\n",
    "extra_feats['session_std'] = ((full_df[times]-datetime(1970,1,1))/np.timedelta64(1, 's')).std(axis=1)\n",
    "# Additional factors for logit\n",
    "extra_feats['weekday'] = full_df[times].min(axis=1).apply(lambda x: x.weekday())\n",
    "extra_feats['yearmonth'] = full_df[times].min(axis=1).apply(lambda x: x.year*12+x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_extra_all = extra_feats.copy().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features for hour\n",
    "# Based on visual analysis above\n",
    "logit_extra_all['low_hours'] = logit_extra_all['start_hour'].isin([9,11,14,15]).astype(int)\n",
    "logit_extra_all['midday'] = logit_extra_all['start_hour'].isin([12,13]).astype(int)\n",
    "logit_extra_all['peak'] = logit_extra_all['start_hour'].isin([16,17]).astype(int)\n",
    "logit_extra_all['evening'] = logit_extra_all['start_hour'].isin([18]).astype(int)\n",
    "logit_extra_all['dead_hours'] = logit_extra_all['start_hour'].isin([0,1,2,3,4,5,6,7,8,10,19,20,21,24]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_extra_all['weekday_0_1'] = logit_extra_all['weekday'].isin([0,1]).astype(int)\n",
    "logit_extra_all['weekday_3_4'] = logit_extra_all['weekday'].isin([3,4]).astype(int)\n",
    "logit_extra_all['weekday_other'] = logit_extra_all['weekday'].isin([2,5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc features based on strings\n",
    "stats = full_sites_strings.apply(domain_stats)\n",
    "\n",
    "logit_extra_all['dom_cnt'] = stats.apply(lambda x: x[0][0])\n",
    "logit_extra_all['dom_unique'] = stats.apply(lambda x: x[0][1])\n",
    "logit_extra_all['subdom_cnt'] = stats.apply(lambda x: x[1][0])\n",
    "logit_extra_all['subdom_unique'] = stats.apply(lambda x: x[1][1])\n",
    "\n",
    "logit_extra_all['su_1'] = logit_extra_all['subdom_unique'].apply(lambda x: 1 if x==1 else 0)\n",
    "logit_extra_all['su_05_1'] = logit_extra_all['subdom_unique'].apply(lambda x: 1 if x<1 and x > 0.5 else 0)\n",
    "logit_extra_all['su_05'] = logit_extra_all['subdom_unique'].apply(lambda x: 1 if x==0.5 else 0)\n",
    "logit_extra_all['su_02_05'] = logit_extra_all['subdom_unique'].apply(lambda x: 1 if x>=0.2 and x<0.5 else 0)\n",
    "logit_extra_all['su_0'] = logit_extra_all['subdom_unique'].apply(lambda x: 1 if x<0.2 else 0)\n",
    "\n",
    "#logit_extra_all['ud_08_1'] = logit_extra_all['dom_unique'].apply(lambda x: 1 if x>0.8 else 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try some combinations\n",
    "# Tried a bunch. What remains are only ones who give a consistent improvement\n",
    "# over OOT cross-validation.\n",
    "logit_extra_all['extra_busy'] = (logit_extra_all['weekday_0_1'] | logit_extra_all['weekday_3_4']) & \\\n",
    "                                (logit_extra_all['midday'] | logit_extra_all['peak'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_extra_all = logit_extra_all.drop(['start_hour','start_minute','weekday',\n",
    "                                        'dom_cnt',\n",
    "                                        'dom_unique',\n",
    "                                        'subdom_cnt','subdom_unique',\n",
    "                                       ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge additional features with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.concat([full_sites_strings.iloc[:idx_split],\n",
    "                            logit_extra_all.iloc[:idx_split,:]],axis=1)\n",
    "all_test_data = pd.concat([full_sites_strings.iloc[idx_split:],\n",
    "                            logit_extra_all.iloc[idx_split:,:]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline\n",
    "__Note:__ We'll scale all the data except for TF-IDF output. TF-IDF transformer output must not be scaled as the different average values of different features are intentional. Details are in the blog post linked in the README to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = tokenize_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipeline = Pipeline([\n",
    "    ('col_transform',ColumnTransformer([\n",
    "        ('site_bag',Pipeline([\n",
    "            ('vect',CountVectorizer(tokenizer=tokenize,max_features=50000, ngram_range=(1,3), stop_words=['www'])),\n",
    "            ('tfidf',TfidfTransformer())\n",
    "        ]),0),\n",
    "        ('extra',StandardScaler(),slice(1,1+logit_extra_all.shape[1]))\n",
    "    ],n_jobs=2)),\n",
    "    ('clf',LogisticRegression(C=1, \n",
    "                              solver='liblinear',random_state=RANDOM_STATE,class_weight=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC score after feature engineering and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8891695 , 0.9647462 , 0.94316376, 0.96375194, 0.91808965,\n",
       "       0.97105816, 0.98533805])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_splitter = TimeSeriesSplit(n_splits=N_FOLDS)\n",
    "cv_res = cross_val_score(estimator=main_pipeline,X=all_train_data,y=y,cv=ts_splitter,n_jobs=7,scoring='roc_auc')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering adn data cleaning model cross-validation ROC AUC score is 0.9562803120927033\n"
     ]
    }
   ],
   "source": [
    "print('Feature engineering adn data cleaning model cross-validation ROC AUC score is {}'.format(np.mean(cv_res[SKIP_FOLDS:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Basic TF-IDF + feature engineering and data cleaning. No hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to reengineer the data. It's enough to just run hypeoptimization. All we need to do is set up a function that will calculate the loss of a hyperoptimization iteration and the hyperopt module will take care of the rest.\n",
    "\n",
    "The loss function will be `-roc_auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is hyperoptimization\n",
    "def objective(space):\n",
    "    \"\"\"\n",
    "    Takes hyperparameters and outputs negative\n",
    "    cross-validation ROC AUC score\n",
    "    \n",
    "    space (dict): dictionary of hyperparameters\n",
    "    Out:\n",
    "    (loss,status): loss is negative ROC AUC score\n",
    "    \"\"\"\n",
    "    #print(space)\n",
    "    main_pipeline = Pipeline([\n",
    "        ('col_transform',ColumnTransformer([\n",
    "            ('site_bag',Pipeline([\n",
    "                ('vect',CountVectorizer(tokenizer=space['vect__tokenizer'],max_features=space['vect__max_features']\n",
    "                                        , ngram_range=(1,space['vect__ngram_max']), stop_words=space['vect__stop_words'])),\n",
    "                ('tfidf',TfidfTransformer())\n",
    "            ]),0),\n",
    "            ('extra',StandardScaler(),slice(1,1+logit_extra_all.shape[1]))\n",
    "        ],n_jobs=2)),\n",
    "        ('clf',LogisticRegression(C=space['clf__C'], \n",
    "                                  solver=space['clf__solver'],random_state=RANDOM_STATE,class_weight=None))\n",
    "    ])\n",
    "    \n",
    "    ts_splitter = TimeSeriesSplit(n_splits=N_FOLDS)\n",
    "    scores = cross_val_score(estimator=main_pipeline,X=all_train_data,y=y,cv=ts_splitter,n_jobs=7,scoring='roc_auc')\n",
    "    loss = -np.mean(scores[SKIP_FOLDS:])\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'vect__tokenizer': tokenize,\n",
    "    'vect__max_features': hp.uniformint('vect__max_features',10000,100000),\n",
    "    'vect__ngram_max': hp.uniformint('vect__ngram_max',1,10),\n",
    "    'vect__stop_words': ['www'],\n",
    "    'clf__C': hp.lognormal('clf__C',np.log(4.5),1),\n",
    "    'clf__solver': 'liblinear'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [45:28<00:00, 61.35s/it, best loss: -0.9662373627447648]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(fn=objective,space=space,algo=tpe.suggest,max_evals=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 23.27535662532287,\n",
       " 'vect__max_features': 46650.0,\n",
       " 'vect__ngram_max': 1.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the result so that we won't have to rerun the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'clf__C': 23.27535662532287,\n",
    " 'vect__max_features': 46650.0,\n",
    " 'vect__ngram_max': 1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "We shouldn't forget to retrain the model on the entire dataset before submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = best\n",
    "settings['vect__max_features'] = int(settings['vect__max_features'])\n",
    "settings['vect__tokenizer'] = tokenize\n",
    "settings['clf__solver'] = 'liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pipeline = Pipeline([\n",
    "    ('col_transform',ColumnTransformer([\n",
    "        ('site_bag',Pipeline([\n",
    "            ('vect',CountVectorizer(tokenizer=settings['vect__tokenizer'],max_features=settings['vect__max_features']\n",
    "                                    , ngram_range=(1,settings['vect__ngram_max']))),\n",
    "            ('tfidf',TfidfTransformer())\n",
    "        ]),0),\n",
    "        ('extra',StandardScaler(),slice(1,1+logit_extra_all.shape[1]))\n",
    "    ],n_jobs=2)),\n",
    "    ('clf',LogisticRegression(C=settings['clf__C'], \n",
    "                              solver=settings['clf__solver'],random_state=RANDOM_STATE,class_weight=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('col_transform',\n",
       "                 ColumnTransformer(n_jobs=2, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('site_bag',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('vect',\n",
       "                                                                   CountVectorizer(analyzer='word',\n",
       "                                                                                   binary=False,\n",
       "                                                                                   decode_error='strict',\n",
       "                                                                                   dtype=<class 'numpy.int64'>,\n",
       "                                                                                   encoding='utf-8',\n",
       "                                                                                   input='content',\n",
       "                                                                                   lowercase=True,\n",
       "                                                                                   max_df=1.0,...\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  slice(1, 18, None))],\n",
       "                                   verbose=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=23.27535662532287, class_weight=None,\n",
       "                                    dual=False, fit_intercept=True,\n",
       "                                    intercept_scaling=1, l1_ratio=None,\n",
       "                                    max_iter=100, multi_class='warn',\n",
       "                                    n_jobs=None, penalty='l2', random_state=42,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipeline.fit(all_train_data,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = main_pipeline.predict_proba(all_test_data)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_to_submission_file(preds, './results/final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
